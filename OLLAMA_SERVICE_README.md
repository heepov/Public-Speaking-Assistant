# Ollama Processing Service

–ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Ollama —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π.

## üöÄ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- ‚úÖ **GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ NVIDIA GPU
- ‚úÖ **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π** - –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
- ‚úÖ **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** - –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ Docker volume –∏ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
- ‚úÖ **–ë—ã—Å—Ç—Ä–∞—è —Å–±–æ—Ä–∫–∞** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
- ‚úÖ **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏** - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ llama2, llama3 –∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
- ‚úÖ **API —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** - REST API –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏/—É–¥–∞–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Main App      ‚îÇ    ‚îÇ Ollama Processing‚îÇ    ‚îÇ   Ollama        ‚îÇ
‚îÇ   (FastAPI)     ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Microservice   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Server        ‚îÇ
‚îÇ   Port: 8000    ‚îÇ    ‚îÇ   Port: 8004     ‚îÇ    ‚îÇ   Port: 11434   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                        ‚îÇ
                              ‚îÇ                        ‚îÇ
                              ‚ñº                        ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   GPU Support   ‚îÇ    ‚îÇ   Models Volume ‚îÇ
                       ‚îÇ   (NVIDIA)      ‚îÇ    ‚îÇ   (Persistent)  ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ë—ã—Å—Ç—Ä–∞—è —Å–±–æ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫

```powershell
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –±—ã—Å—Ç—Ä–æ–π —Å–±–æ—Ä–∫–∏
.\scripts\docker-build-ollama-fast.ps1
```

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
- –ü—Ä–æ–≤–µ—Ä–∏—Ç Docker –∏ NVIDIA Docker
- –°–æ–±–µ—Ä–µ—Ç –æ–±—Ä–∞–∑ ollama-processing
- –ó–∞–ø—É—Å—Ç–∏—Ç —Å–µ—Ä–≤–∏—Å—ã ollama –∏ ollama-processing
- –ü—Ä–æ–≤–µ—Ä–∏—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API

### 2. –†—É—á–Ω–∞—è —Å–±–æ—Ä–∫–∞

```powershell
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
docker-compose -f app/docker/docker-compose.yml stop ollama ollama-processing

# –°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑
docker-compose -f app/docker/docker-compose.yml build ollama-processing

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã
docker-compose -f app/docker/docker-compose.yml up -d ollama ollama-processing
```

## üì° API Endpoints

### –û—Å–Ω–æ–≤–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã

| –ú–µ—Ç–æ–¥ | –≠–Ω–¥–ø–æ–∏–Ω—Ç | –û–ø–∏—Å–∞–Ω–∏–µ |
|-------|----------|----------|
| `POST` | `/process` | –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏ |
| `GET` | `/models` | –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π |
| `POST` | `/models/install` | –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ |
| `DELETE` | `/models/{model_name}` | –£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ |
| `GET` | `/models/info` | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ –∏ –º–æ–¥–µ–ª—è—Ö |
| `GET` | `/health` | –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞ |

### –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

#### 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏

```bash
curl -X POST http://localhost:8004/process \
  -F 'prompt=–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ Python' \
  -F 'task_id=test123' \
  -F 'model_name=llama2'
```

#### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏

```bash
curl -X POST http://localhost:8004/models/install \
  -F 'model_name=llama3:8b'
```

#### 3. –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

```bash
curl http://localhost:8004/models
```

#### 4. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ

```bash
curl http://localhost:8004/models/info
```

## ü§ñ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### Llama 2
- `llama2` - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (7B)
- `llama2:7b` - 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- `llama2:13b` - 13B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤  
- `llama2:70b` - 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### Llama 3
- `llama3` - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (8B)
- `llama3:8b` - 8B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- `llama3:70b` - 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
- `mistral` - Mistral 7B
- `codellama` - Code Llama
- `neural-chat` - Intel Neural Chat
- `vicuna` - Vicuna

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```powershell
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
.\scripts\test-ollama-api.ps1
```

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
- –ü—Ä–æ–≤–µ—Ä–∏—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- –í—ã–ø–æ–ª–Ω–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–∞ —Å –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª—å—é
- –ü–æ–∫–∞–∂–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```powershell
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API
Invoke-RestMethod -Uri "http://localhost:8004/health"

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
Invoke-RestMethod -Uri "http://localhost:8004/models"

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
$body = @{ model_name = "llama2" }
Invoke-RestMethod -Uri "http://localhost:8004/models/install" -Method POST -Form $body

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
$body = @{
    prompt = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
    task_id = "test123"
    model_name = "llama2"
}
Invoke-RestMethod -Uri "http://localhost:8004/process" -Method POST -Form $body
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

| –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|------------|----------------------|----------|
| `OLLAMA_HOST` | `ollama:11434` | –ê–¥—Ä–µ—Å Ollama —Å–µ—Ä–≤–µ—Ä–∞ |
| `PORT` | `8004` | –ü–æ—Ä—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ |
| `CUDA_VISIBLE_DEVICES` | `0` | GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ |
| `LOG_LEVEL` | `INFO` | –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è |

### Docker Volumes

- `ollama-models` - –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- `uploads` - –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
- `outputs` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
- `logs` - –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

## üêõ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º—ã —Å GPU

```powershell
# –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
docker exec -it ollama-processing nvidia-smi
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å –º–æ–¥–µ–ª—è–º–∏

```powershell
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
curl http://localhost:11434/api/tags

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Ollama
docker logs ollama

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ Ollama
docker-compose -f app/docker/docker-compose.yml restart ollama
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å API

```powershell
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
docker logs ollama-processing

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
curl http://localhost:8004/health

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
docker-compose -f app/docker/docker-compose.yml restart ollama-processing
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –õ–æ–≥–∏

```powershell
# –õ–æ–≥–∏ Ollama —Å–µ—Ä–≤–µ—Ä–∞
docker logs -f ollama

# –õ–æ–≥–∏ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
docker logs -f ollama-processing

# –í—Å–µ –ª–æ–≥–∏
docker-compose -f app/docker/docker-compose.yml logs -f
```

### –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤

```powershell
# –°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
docker-compose -f app/docker/docker-compose.yml ps

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
docker stats ollama ollama-processing
```

## üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞

```powershell
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã
docker-compose -f app/docker/docker-compose.yml stop ollama-processing

# –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑
docker-compose -f app/docker/docker-compose.yml build ollama-processing

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã
docker-compose -f app/docker/docker-compose.yml up -d ollama-processing
```

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

```powershell
# –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å
curl -X POST http://localhost:8004/models/install -F 'model_name=llama2'

# –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
curl -X DELETE http://localhost:8004/models/llama2:old
```

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### Python –∫–ª–∏–µ–Ω—Ç

```python
import requests

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
response = requests.post('http://localhost:8004/process', data={
    'prompt': '–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ñ–∏–∑–∏–∫—É –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏',
    'task_id': 'quantum_physics',
    'model_name': 'llama3:8b'
})

print(response.json()['result'])

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
requests.post('http://localhost:8004/models/install', data={
    'model_name': 'llama3:70b'
})
```

### JavaScript –∫–ª–∏–µ–Ω—Ç

```javascript
// –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
const response = await fetch('http://localhost:8004/process', {
    method: 'POST',
    body: new FormData({
        prompt: '–ù–∞–ø–∏—à–∏ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏',
        task_id: 'poem',
        model_name: 'llama2'
    })
});

const result = await response.json();
console.log(result.result);
```

## üéØ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

1. **–ë—ã—Å—Ç—Ä–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞** - –Ω–µ –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å 15 –º–∏–Ω—É—Ç –Ω–∞ –ø–µ—Ä–µ—Å–±–æ—Ä–∫—É
2. **–≠–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞** - –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
3. **–ì–∏–±–∫–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
4. **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å** - –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏
5. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - –ø–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ GPU
6. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: `docker logs ollama-processing`
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: `nvidia-smi`
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API: `curl http://localhost:8004/health`
4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–∏—Å—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
