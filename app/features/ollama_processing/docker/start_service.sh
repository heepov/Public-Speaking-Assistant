#!/bin/bash

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
cleanup() {
    echo "üõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã..."
    if [ ! -z "$OLLAMA_PID" ]; then
        echo "üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Ollama —Å–µ—Ä–≤–µ—Ä (PID: $OLLAMA_PID)..."
        kill $OLLAMA_PID 2>/dev/null
        wait $OLLAMA_PID 2>/dev/null
    fi
    if [ ! -z "$MICROSERVICE_PID" ]; then
        echo "üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å (PID: $MICROSERVICE_PID)..."
        kill $MICROSERVICE_PID 2>/dev/null
        wait $MICROSERVICE_PID 2>/dev/null
    fi
    echo "‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
    exit 0
}

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
trap cleanup SIGTERM SIGINT

echo "üöÄ –ó–∞–ø—É—Å–∫ Ollama Processing Service..."

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export OLLAMA_HOST=${OLLAMA_HOST:-"localhost:11434"}
export PORT=${PORT:-8004}
export HOST=${HOST:-"0.0.0.0"}
export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-"0"}
export OLLAMA_MODELS=${OLLAMA_MODELS:-"/app/app/features/ollama_processing/models_cache"}

echo "üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏:"
echo "   OLLAMA_HOST: $OLLAMA_HOST"
echo "   PORT: $PORT"
echo "   HOST: $HOST"
echo "   CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
echo "   OLLAMA_MODELS: $OLLAMA_MODELS"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU..."
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ NVIDIA GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω:"
    nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits
else
    echo "‚ö†Ô∏è  NVIDIA GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU"
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Python –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º Python –æ–∫—Ä—É–∂–µ–Ω–∏–µ..."
python --version
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}')"
python -c "import torch; print(f'CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}')"
python -c "import torch; print(f'CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ 0: {torch.cuda.get_device_name(0)}')"
python -c "import ollama; print('Ollama –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω')"
python -c "import fastapi; print('FastAPI –¥–æ—Å—Ç—É–ø–µ–Ω')"

# –ó–∞–ø—É—Å–∫–∞–µ–º Ollama —Å–µ—Ä–≤–µ—Ä –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
echo "üöÄ –ó–∞–ø—É—Å–∫ Ollama —Å–µ—Ä–≤–µ—Ä–∞..."
echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ ollama –¥–æ—Å—Ç—É–ø–µ–Ω..."
which ollama
ollama --version

echo "üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º ollama serve..."
# –£–±–∏–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã ollama –µ—Å–ª–∏ –µ—Å—Ç—å
pkill -f "ollama serve" || true
sleep 2

ollama serve &
OLLAMA_PID=$!
echo "üìù Ollama PID: $OLLAMA_PID"

# –ñ–¥–µ–º, –ø–æ–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä–∞..."
max_attempts=60
attempt=1

while [ $attempt -le $max_attempts ]; do
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å Ollama –≤—Å–µ –µ—â–µ –∂–∏–≤
    if ! kill -0 $OLLAMA_PID 2>/dev/null; then
        echo "‚ùå –ü—Ä–æ—Ü–µ—Å—Å Ollama (PID: $OLLAMA_PID) –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ"
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞..."
        ps aux | grep ollama
        exit 1
    fi
    
    if curl -s http://$OLLAMA_HOST/api/tags > /dev/null 2>&1; then
        echo "‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω"
        break
    else
        echo "‚è≥ –ü–æ–ø—ã—Ç–∫–∞ $attempt/$max_attempts: Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∂–¥–µ–º..."
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã..."
        ps aux | grep ollama
        sleep 5
        attempt=$((attempt + 1))
    fi
done

if [ $attempt -gt $max_attempts ]; then
    echo "‚ùå Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É http://$OLLAMA_HOST –ø–æ—Å–ª–µ $max_attempts –ø–æ–ø—ã—Ç–æ–∫"
    echo "üí° –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞..."
    curl -v http://$OLLAMA_HOST/api/tags || echo "–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å Ollama –µ—Å–ª–∏ –æ–Ω –∑–∞–ø—É—â–µ–Ω
    if [ ! -z "$OLLAMA_PID" ]; then
        kill $OLLAMA_PID 2>/dev/null
    fi
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
echo "üìÅ –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π..."
if [ ! -d "$OLLAMA_MODELS" ]; then
    echo "   –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: $OLLAMA_MODELS"
    mkdir -p "$OLLAMA_MODELS"
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
echo "üì¶ –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏..."
models_response=$(curl -s http://$OLLAMA_HOST/api/tags)
if [ $? -eq 0 ]; then
    models=$(echo "$models_response" | jq -r '.models[].name' 2>/dev/null || echo "")
    if [ -n "$models" ]; then
        echo "   –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:"
        echo "$models" | while read -r model; do
            echo "   - $model"
        done
    else
        echo "   –ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
    fi
else
    echo "   –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π"
fi

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
echo "üöÄ –ó–∞–ø—É—Å–∫ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ Ollama Processing..."
python -m app.features.ollama_processing.microservice &
MICROSERVICE_PID=$!

echo "‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∑–∞–ø—É—â–µ–Ω—ã:"
echo "   - Ollama —Å–µ—Ä–≤–µ—Ä (PID: $OLLAMA_PID)"
echo "   - –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å (PID: $MICROSERVICE_PID)"
echo "   - –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:$PORT"

# –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
wait $MICROSERVICE_PID
