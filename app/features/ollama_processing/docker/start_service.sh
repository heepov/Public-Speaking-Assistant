#!/bin/bash

echo "üöÄ –ó–∞–ø—É—Å–∫ Ollama Processing Service..."

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export OLLAMA_HOST=${OLLAMA_HOST:-"ollama:11434"}
export PORT=${PORT:-8004}
export HOST=${HOST:-"0.0.0.0"}
export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-"0"}

echo "üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏:"
echo "   OLLAMA_HOST: $OLLAMA_HOST"
echo "   PORT: $PORT"
echo "   HOST: $HOST"
echo "   CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU..."
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ NVIDIA GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω:"
    nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits
else
    echo "‚ö†Ô∏è  NVIDIA GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU"
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Python –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º Python –æ–∫—Ä—É–∂–µ–Ω–∏–µ..."
python --version
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}')"
python -c "import torch; print(f'CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}')"
python -c "import torch; print(f'CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ 0: {torch.cuda.get_device_name(0)}')"
python -c "import ollama; print('Ollama –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω')"
python -c "import fastapi; print('FastAPI –¥–æ—Å—Ç—É–ø–µ–Ω')"

# –ñ–¥–µ–º, –ø–æ–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è
echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä–∞..."
max_attempts=60
attempt=1

while [ $attempt -le $max_attempts ]; do
    if curl -s http://$OLLAMA_HOST/api/tags > /dev/null 2>&1; then
        echo "‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω"
        break
    else
        echo "‚è≥ –ü–æ–ø—ã—Ç–∫–∞ $attempt/$max_attempts: Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∂–¥–µ–º..."
        sleep 5
        attempt=$((attempt + 1))
    fi
done

if [ $attempt -gt $max_attempts ]; then
    echo "‚ùå Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É http://$OLLAMA_HOST –ø–æ—Å–ª–µ $max_attempts –ø–æ–ø—ã—Ç–æ–∫"
    echo "üí° –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞..."
    curl -v http://$OLLAMA_HOST/api/tags || echo "–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
echo "üì¶ –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏..."
models_response=$(curl -s http://$OLLAMA_HOST/api/tags)
if [ $? -eq 0 ]; then
    models=$(echo "$models_response" | jq -r '.models[].name' 2>/dev/null || echo "")
    if [ -n "$models" ]; then
        echo "   –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:"
        echo "$models" | while read -r model; do
            echo "   - $model"
        done
    else
        echo "   –ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
    fi
else
    echo "   –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π"
fi

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å
echo "üöÄ –ó–∞–ø—É—Å–∫ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ Ollama Processing..."
python -m app.features.ollama_processing.microservice
